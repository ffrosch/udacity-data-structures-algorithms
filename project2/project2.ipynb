{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Least Recently Used (LRU) Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have briefly discussed caching as part of a practice problem while studying hash maps.\n",
    "\n",
    "The lookup operation (i.e., `get()`) and `put()` / `set()` is supposed to be fast for a cache memory.\n",
    "\n",
    "While doing the `get()` operation, if the entry is found in the cache, it is known as a `cache hit`. If, however, the entry is not found, it is known as a `cache miss`.\n",
    "\n",
    "When designing a cache, we also place an upper bound on the size of the cache. If the cache is full and we want to add a new entry to the cache, we use some criteria to remove an element. After removing an element, we use the `put()` operation to insert the new element. The remove operation should also be fast.\n",
    "\n",
    "For our first problem, the goal will be to design a data structure known as a **Least Recently Used (LRU) cache**. An LRU cache is a type of cache in which we remove the least recently used entry when the cache memory reaches its limit. For the current problem, consider both `get` and `set` operations as an `use operation`.\n",
    "\n",
    "Your job is to use an appropriate data structure(s) to implement the cache.\n",
    "\n",
    "- In case of a `cache hit`, your `get()` operation should return the appropriate value.\n",
    "- In case of a `cache miss`, your `get()` should return -1.\n",
    "- While putting an element in the cache, your `put()` / `set()` operation must insert the element. If the cache is full, you must write code that removes the least recently used entry first and then insert the element.\n",
    "\n",
    "All operations must take `O(1)` time.\n",
    "\n",
    "For the current problem, you can consider the `size of cache = 5`.\n",
    "\n",
    "Here is some boiler plate code and some example test cases to get you started on this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "\n",
    "class Node:\n",
    "    _id_generator = itertools.count()\n",
    "\n",
    "    def __init__(self, prev: 'Node', next: 'Node', key: int, value: int):\n",
    "        self.id: int = self._id_generator.__next__()\n",
    "        self.prev = prev\n",
    "        self.next = next\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Node (id: {self.id}, prev: {self.prev.id if type(self.prev) is type(self) else None}, next: {self.next.id if type(self.next) is type(self) else None}, {{{self.key}: {self.value}}})'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            self.prev is other.prev and\n",
    "            self.next is other.next and\n",
    "            self.key == other.key and\n",
    "            self.value == other.value\n",
    "        )\n",
    "\n",
    "class DoublyLinkedCircularList:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.size: int = 0\n",
    "        self.root: Node = Node(None, None, None, None)\n",
    "        self.root.prev = self.root\n",
    "        self.root.next = self.root\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = '['\n",
    "        link = self.root\n",
    "        while True:\n",
    "            s += f'{link}'\n",
    "            link = link.next\n",
    "            if link is self.root:\n",
    "                break\n",
    "            else:\n",
    "                s += ',\\n'\n",
    "        s += ']'\n",
    "        return s\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def add_item(self, key: int, value: int) -> Node:\n",
    "        if self.size == 0:\n",
    "            self.root.key = key\n",
    "            self.root.value = value\n",
    "            link = self.root\n",
    "        else:\n",
    "            root = self.root\n",
    "            last = root.prev\n",
    "            link = Node(last, root, key, value)\n",
    "            last.next = root.prev = link\n",
    "        self.size += 1\n",
    "\n",
    "        return link\n",
    "\n",
    "    def replace_oldest_node(self, key: int, value: int) -> Tuple[Node, Node]:\n",
    "        old_link, last, self.root = self.root, self.root.prev, self.root.next\n",
    "        new_link = Node(last, self.root, key, value)\n",
    "        last.next, self.root.prev = new_link, new_link\n",
    "        return old_link, new_link\n",
    "\n",
    "    def update_node(self, link: Node):\n",
    "        # in a circular linked list the last item precedes root\n",
    "        last = self.root.prev\n",
    "        # no need to update\n",
    "        if link is last:\n",
    "            return\n",
    "\n",
    "        # edge case -> new root node\n",
    "        if link is self.root:\n",
    "            self.root = self.root.next\n",
    "\n",
    "        # connect old neighbours of the link (bridge gap)\n",
    "        # necessary if updated link is NOT root\n",
    "        link.prev.next = link.next\n",
    "        link.next.prev = link.prev\n",
    "        \n",
    "        # put updated node at the end of the list\n",
    "        # update new neighbours to point to link (insert link)\n",
    "        last.next = link\n",
    "        self.root.prev = link\n",
    "\n",
    "        # update link to point to new neighbours\n",
    "        link.next = self.root\n",
    "        link.prev = last\n",
    "    \n",
    "\n",
    "class LRU_Cache:\n",
    "\n",
    "    def _cache_capacity_warning(self):\n",
    "        warnings.warn('Cache capacity is 0. No items will be stored.', UserWarning)\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        self.cache = {}\n",
    "        self.list = DoublyLinkedCircularList()\n",
    "        self.cap = capacity\n",
    "\n",
    "        if self.cap == 0:\n",
    "            self._cache_capacity_warning()\n",
    "\n",
    "    def get(self, key: int) -> int:\n",
    "        # Retrieve item from provided key. Return -1 if nonexistent.\n",
    "        if self.cap == 0:\n",
    "            self._cache_capacity_warning() \n",
    "        result = self.cache.get(key, None)\n",
    "        if result is not None:\n",
    "            self.list.update_node(result)\n",
    "            return result.value\n",
    "        return -1\n",
    "\n",
    "    def set(self, key: int, value: int):\n",
    "        # Set the value if the key is not present in the cache. If the cache is at capacity remove the oldest item. \n",
    "        if self.cap == 0:\n",
    "            self._cache_capacity_warning()\n",
    "            return\n",
    "\n",
    "        if key in self.cache:\n",
    "            link = self.cache.get(key)\n",
    "            self.list.update_node(link)\n",
    "            link.value = value\n",
    "        elif self.cache_full:\n",
    "            old_link, new_link = self.list.replace_oldest_node(key, value)\n",
    "            del self.cache[old_link.key]\n",
    "            del old_link\n",
    "            self.cache[key] = new_link\n",
    "        else:\n",
    "            link = self.list.add_item(key, value)\n",
    "            self.cache[key] = link\n",
    "\n",
    "    @property\n",
    "    def cache_full(self):\n",
    "        return self.list.size == self.cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_add_item (__main__.TestCircularDoublyLinkedList) ... ok\n",
      "test_init (__main__.TestCircularDoublyLinkedList) ... ok\n",
      "test_replace_oldest_node (__main__.TestCircularDoublyLinkedList) ... ok\n",
      "test_update_last_node (__main__.TestCircularDoublyLinkedList)\n",
      "Test the edge case where the last node gets updated. ... ok\n",
      "test_update_node (__main__.TestCircularDoublyLinkedList)\n",
      "Test node update procedure. ... ok\n",
      "test_update_root_node (__main__.TestCircularDoublyLinkedList)\n",
      "Test edge case where the root node gets updated. ... ok\n",
      "test_get (__main__.TestLRU_Cache) ... ok\n",
      "test_get_changes_lru_order (__main__.TestLRU_Cache) ... ok\n",
      "test_get_existing_key_use_operation (__main__.TestLRU_Cache) ... ok\n",
      "test_lru_remove_least_used (__main__.TestLRU_Cache) ... ok\n",
      "test_set (__main__.TestLRU_Cache) ... ok\n",
      "test_set_existing_key_use_operation (__main__.TestLRU_Cache) ... ok\n",
      "test_zero_capacity (__main__.TestLRU_Cache)\n",
      "Test edge case with zero cache capacity. ... /tmp/ipykernel_6333/1177060804.py:100: UserWarning: Cache capacity is 0. No items will be stored.\n",
      "  warnings.warn('Cache capacity is 0. No items will be stored.', UserWarning)\n",
      "/tmp/ipykernel_6333/1177060804.py:100: UserWarning: Cache capacity is 0. No items will be stored.\n",
      "  warnings.warn('Cache capacity is 0. No items will be stored.', UserWarning)\n",
      "ok\n",
      "test_create_empty_node (__main__.TestNode) ... ok\n",
      "test_node_key_value (__main__.TestNode) ... ok\n",
      "test_node_link (__main__.TestNode) ... ok\n",
      "test_node_repr (__main__.TestNode) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 17 tests in 0.030s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f1ec4470e50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class TestNode(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.key = 1\n",
    "        self.value = 2\n",
    "\n",
    "        self.node1 = Node(None, None, None, None)\n",
    "        self.node2 = Node(self.node1, None, None, None)\n",
    "        self.node3 = Node(self.node2, self.node1, self.key, self.value)\n",
    "\n",
    "    def test_create_empty_node(self):\n",
    "        # require arguments for Node()\n",
    "        self.assertRaises(TypeError, Node)\n",
    "        \n",
    "    def test_node_link(self):\n",
    "        self.node1.prev = self.node3\n",
    "        self.node1.next = self.node2\n",
    "        self.node2.next = self.node3\n",
    "\n",
    "        self.assertIs(self.node2.next, self.node3)\n",
    "        self.assertIs(self.node1.next, self.node2)\n",
    "        self.assertIs(self.node3.next, self.node1)\n",
    "\n",
    "        self.assertIs(self.node2.prev, self.node1)\n",
    "        self.assertIs(self.node1.prev, self.node3)\n",
    "        self.assertIs(self.node3.prev, self.node2)\n",
    "\n",
    "    def test_node_key_value(self):\n",
    "        self.assertEqual(self.node3.key, self.key)\n",
    "        self.assertEqual(self.node3.value, self.value)\n",
    "\n",
    "    def test_node_repr(self):\n",
    "        self.assertEqual(repr(self.node1), f\"Node (id: {self.node1.id}, prev: None, next: None, {{None: None}})\")\n",
    "        self.assertEqual(repr(self.node2), f\"Node (id: {self.node2.id}, prev: {self.node1.id}, next: None, {{None: None}})\")\n",
    "        self.assertEqual(repr(self.node3), f\"Node (id: {self.node3.id}, prev: {self.node2.id}, next: {self.node1.id}, {{{self.key}: {self.value}}})\")\n",
    "\n",
    "\n",
    "class TestCircularDoublyLinkedList(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.list = DoublyLinkedCircularList()\n",
    "        self.list.add_item(1, 1)\n",
    "        self.list.add_item(2, 2)\n",
    "        self.list.add_item(3, 3)\n",
    "    \n",
    "    def test_init(self):\n",
    "        list = DoublyLinkedCircularList()\n",
    "        self.assertIs(list.root, list.root.prev)\n",
    "        self.assertIs(list.root, list.root.next)\n",
    "        self.assertEqual(list.size, 0)\n",
    "\n",
    "    def test_add_item(self):\n",
    "        self.assertEqual(self.list.size, 3)\n",
    "        node = self.list.add_item(4, 4)\n",
    "        self.assertIs(type(node), Node)\n",
    "        self.assertEqual(self.list.size, 4)\n",
    "\n",
    "    def test_replace_oldest_node(self):\n",
    "        size = self.list.size\n",
    "\n",
    "        oldest = self.list.root\n",
    "        old, new = self.list.replace_oldest_node(4, 4)\n",
    "        newest = self.list.root.prev\n",
    "        # check that the removed node was really the oldest\n",
    "        self.assertIs(old, oldest)\n",
    "        # check that the new node is really at the \"end\" of the list\n",
    "        self.assertIs(new, newest)\n",
    "\n",
    "        # check that the old node was removed from the list\n",
    "        node = self.list.root\n",
    "        while True:\n",
    "            self.assertIsNot(old, node)\n",
    "            node = node.next\n",
    "            if node is self.list.root:\n",
    "                break\n",
    "        \n",
    "        # size should not have changed\n",
    "        self.assertEqual(self.list.size, size)\n",
    "\n",
    "    def test_update_node(self):\n",
    "        \"\"\"Test node update procedure.\"\"\"\n",
    "        root = self.list.root\n",
    "        last = root.prev\n",
    "        node = root.next\n",
    "\n",
    "        node_prev = node.prev\n",
    "        node_next = node.next\n",
    "\n",
    "        self.list.update_node(node)\n",
    "\n",
    "        # Updated node moved to end of list\n",
    "        self.assertIs(node, root.prev)\n",
    "        self.assertIs(node, last.next)\n",
    "        # References of node were updated correctly\n",
    "        self.assertIs(node.prev, last)\n",
    "        self.assertIs(node.next, root)\n",
    "        # Old neighbours were updated correctly\n",
    "        # Node was inserted at the end, leaving a gap that had to be filled\n",
    "        self.assertIs(node_prev.next, node_next)\n",
    "        self.assertIs(node_next.prev, node_prev)\n",
    "\n",
    "\n",
    "    def test_update_root_node(self):\n",
    "        \"\"\"Test edge case where the root node gets updated.\"\"\"\n",
    "        root = self.list.root\n",
    "        last = root.prev\n",
    "        node = root\n",
    "\n",
    "        node_prev = node.prev\n",
    "        node_next = node.next\n",
    "\n",
    "        self.list.update_node(node)\n",
    "\n",
    "        # Reference the new root\n",
    "        self.assertIsNot(root, self.list.root)\n",
    "\n",
    "        # reassign root\n",
    "        root = self.list.root\n",
    "\n",
    "        # Updated node moved to end of list\n",
    "        self.assertIs(node, root.prev)\n",
    "        self.assertIs(node, last.next)\n",
    "        # References of node were updated correctly\n",
    "        self.assertIs(node.prev, last)\n",
    "        self.assertIs(node.next, root)\n",
    "        # Old neighbours were updated correctly\n",
    "        # Order did not change, all nodes just got rotated\n",
    "        self.assertIs(node_prev.next, node)\n",
    "        self.assertIs(node_next.prev, node)\n",
    "\n",
    "        self.assertIsNot(node, root)\n",
    "\n",
    "    def test_update_last_node(self):\n",
    "        \"\"\"Test the edge case where the last node gets updated.\"\"\"\n",
    "        root = self.list.root\n",
    "        last = root.prev\n",
    "        node = last\n",
    "\n",
    "        node_prev = node.prev\n",
    "        node_next = node.next\n",
    "\n",
    "        self.list.update_node(node)\n",
    "\n",
    "        # Updated node did not move\n",
    "        self.assertIs(node, node_prev.next)\n",
    "        self.assertIs(node, node_next.prev)\n",
    "        self.assertIs(node, self.list.root.prev)\n",
    "        self.assertIs(node.next, self.list.root)\n",
    "        # References of node were not changed\n",
    "        self.assertIs(node.prev, node_prev)\n",
    "        self.assertIs(node.next, node_next)\n",
    "\n",
    "\n",
    "class TestLRU_Cache(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.c = LRU_Cache(5)\n",
    "        self.c.set(1, 1)\n",
    "        self.c.set(2, 2)\n",
    "        self.c.set(3, 3)\n",
    "        self.c.set(4, 4)\n",
    "        self.c.set(5, 5)\n",
    "    \n",
    "    def test_zero_capacity(self):\n",
    "        \"\"\"Test edge case with zero cache capacity.\n",
    "        \n",
    "        No erros, only warnings should occur.\n",
    "        \"\"\"\n",
    "        c = LRU_Cache(0)\n",
    "        c.set(1, 1)\n",
    "\n",
    "        self.assertWarns(UserWarning, LRU_Cache, 0)\n",
    "        self.assertWarns(UserWarning, c.get, 1)\n",
    "        self.assertWarns(UserWarning, c.set, 1, 1)\n",
    "        self.assertEqual(c.get(1), -1)\n",
    "\n",
    "    def test_get(self):\n",
    "        self.assertEqual(self.c.get(1), 1)\n",
    "        self.assertEqual(self.c.get(2), 2)\n",
    "        self.assertEqual(self.c.get(3), 3)\n",
    "        self.assertEqual(self.c.get(4), 4)\n",
    "        self.assertEqual(self.c.get(5), 5)\n",
    "\n",
    "    def test_get_changes_lru_order(self):\n",
    "        self.c.get(1)\n",
    "        self.c.get(2)\n",
    "        order = [3, 4, 5, 1, 2]\n",
    "        lru = []\n",
    "        node = self.c.list.root\n",
    "        for i in range(5):\n",
    "            lru.append(node.value)\n",
    "            node = node.next\n",
    "        self.assertEqual(lru, order)\n",
    "\n",
    "    def test_lru_remove_least_used(self):\n",
    "        self.assertEqual(self.c.cache.get(1).value, 1)\n",
    "        self.c.set(6, 6)\n",
    "        self.assertEqual(self.c.cache.get(1), None)\n",
    "        self.assertEqual(self.c.get(1), -1)\n",
    "\n",
    "    def test_set(self):\n",
    "        self.c.set(7, 7)\n",
    "        self.assertEqual(self.c.get(7), 7)\n",
    "        self.c.set(7, 8)\n",
    "        self.assertEqual(self.c.get(7), 8)\n",
    "\n",
    "    def test_set_existing_key_use_operation(self):\n",
    "        self.c.set(1, 1)\n",
    "        last_used_key = self.c.list.root.prev.key\n",
    "        self.assertEqual(last_used_key, 1)\n",
    "    \n",
    "    def test_get_existing_key_use_operation(self):\n",
    "        self.c.get(1)\n",
    "        last_used_key = self.c.list.root.prev.key\n",
    "        self.assertEqual(last_used_key, 1)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()\n",
    "\n",
    "# Run unittest in Jupyterlab\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cache:\n",
      "[Node (id: 35, prev: 38, next: 36, {1: 1}),\n",
      "Node (id: 36, prev: 35, next: 37, {2: 2}),\n",
      "Node (id: 37, prev: 36, next: 38, {3: 3}),\n",
      "Node (id: 38, prev: 37, next: 35, {4: 4})]\n",
      "1\n",
      "2\n",
      "-1\n",
      "-1\n",
      "6\n",
      "5\n",
      "Final Cache:\n",
      "[Node (id: 38, prev: 40, next: 35, {4: 4}),\n",
      "Node (id: 35, prev: 38, next: 36, {1: 1}),\n",
      "Node (id: 36, prev: 35, next: 39, {2: 2}),\n",
      "Node (id: 39, prev: 36, next: 40, {5: 5}),\n",
      "Node (id: 40, prev: 39, next: 38, {6: 6})]\n"
     ]
    }
   ],
   "source": [
    "our_cache = LRU_Cache(5)\n",
    "\n",
    "our_cache.set(1, 1)\n",
    "our_cache.set(2, 2)\n",
    "our_cache.set(3, 3)\n",
    "our_cache.set(4, 4)\n",
    "print('Initial Cache:', our_cache.list, sep='\\n')\n",
    "\n",
    "print(our_cache.get(1))       # returns 1\n",
    "print(our_cache.get(2))       # returns 2\n",
    "print(our_cache.get(9))       # returns -1 because 9 is not present in the cache\n",
    "\n",
    "our_cache.set(5, 5)\n",
    "our_cache.set(6, 6)\n",
    "\n",
    "print(our_cache.get(3))      # returns -1 because the cache reached it's capacity and 3 was the least recently used entry\n",
    "print(our_cache.get(6))      # returns 6\n",
    "print(our_cache.get(5))      # returns 5\n",
    "our_cache.set(6, 6)          # update node 6\n",
    "print('Final Cache:', our_cache.list, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: File Recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, the goal is to write code for finding all files under a directory (and all directories beneath it) that end with `.c`\n",
    "\n",
    "Here is an example of a test directory listing, which can be downloaded [here](https://s3.amazonaws.com/udacity-dsand/testdir.zip):\n",
    "\n",
    "```shell\n",
    "./testdir\n",
    "./testdir/subdir1\n",
    "./testdir/subdir1/a.c\n",
    "./testdir/subdir1/a.h\n",
    "./testdir/subdir2\n",
    "./testdir/subdir2/.gitkeep\n",
    "./testdir/subdir3\n",
    "./testdir/subdir3/subsubdir1\n",
    "./testdir/subdir3/subsubdir1/b.c\n",
    "./testdir/subdir3/subsubdir1/b.h\n",
    "./testdir/subdir4\n",
    "./testdir/subdir4/.gitkeep\n",
    "./testdir/subdir5\n",
    "./testdir/subdir5/a.c\n",
    "./testdir/subdir5/a.h\n",
    "./testdir/t1.c\n",
    "./testdir/t1.h\n",
    "```\n",
    "\n",
    "Python's `os` module will be useful—in particular, you may want to use the following resources:\n",
    "\n",
    "`os.path.isdir(path)`\n",
    "\n",
    "`os.path.isfile(path)`\n",
    "\n",
    "`os.listdir(directory)`\n",
    "\n",
    "`os.path.join(...)`\n",
    "\n",
    "Note: `os.walk()` is a handy Python method which can achieve this task very easily. However, for this problem you are not allowed to use `os.walk()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./testdir/subdir1/a.c', './testdir/t1.c', './testdir/subdir5/a.c', './testdir/subdir3/subsubdir1/b.c']\n",
      "ValueError: '.' is not a valid suffix!\n",
      "ValueError: path must be a directory!\n",
      "['./testdir/subdir2/.gitkeep', './testdir/subdir4/.gitkeep']\n",
      "[]\n",
      "ValueError: 'a.c' is not a valid suffix!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def find_files(suffix, path):\n",
    "    \"\"\"\n",
    "    Find all files beneath path with file name suffix.\n",
    "\n",
    "    Note that a path may contain further subdirectories\n",
    "    and those subdirectories may also contain further subdirectories.\n",
    "\n",
    "    There are no limit to the depth of the subdirectories can be.\n",
    "\n",
    "    Args:\n",
    "      suffix(str): suffix of the file name to be found\n",
    "        valid forms are e.g. '.doc' and 'doc'\n",
    "      path(str): path of the file system\n",
    "\n",
    "    Returns:\n",
    "       a list of paths\n",
    "    \"\"\"\n",
    "    matched_files = []\n",
    "\n",
    "    match suffix:\n",
    "        case \"\":\n",
    "            return \"ValueError: suffix can't be an empty string!\"\n",
    "        case None:\n",
    "            return \"ValueError: suffix can't be None!\"\n",
    "        case \".\":\n",
    "            return \"ValueError: '.' is not a valid suffix!\"\n",
    "        case str(p) if p.find(\".\") > 0:\n",
    "            return f\"ValueError: '{suffix}' is not a valid suffix!\"\n",
    "\n",
    "    match path:\n",
    "        case \"\":\n",
    "            return \"ValueError: path can't be an empty string!\"\n",
    "        case None:\n",
    "            return \"ValueError: path can't be  None!\"\n",
    "        case str(p) if not os.path.isdir(p):\n",
    "            return \"ValueError: path must be a directory!\"\n",
    "\n",
    "    # remove '.' at the beginning\n",
    "    suffix = suffix[1:] if suffix[0] == '.' else suffix\n",
    "\n",
    "    for child in os.listdir(path):\n",
    "        child_path = os.path.join(path, child)\n",
    "\n",
    "        if os.path.isfile(child_path):\n",
    "            \n",
    "            if child_path.split('.')[-1] == suffix:\n",
    "                matched_files.append(child_path)\n",
    "\n",
    "        if os.path.isdir(child_path):\n",
    "            matched_files.extend(find_files(suffix, child_path))\n",
    "\n",
    "    return matched_files\n",
    "\n",
    "\n",
    "print(find_files('.c', './'))\n",
    "# ['./testdir/subdir1/a.c', './testdir/t1.c', './testdir/subdir5/a.c', './testdir/subdir3/subsubdir1/b.c']\n",
    "print(find_files('.', './'))\n",
    "# ValueError: '.' is not a valid suffix!\n",
    "print(find_files('.c', './dir-does-not-exist'))\n",
    "# ValueError: path must be a directory!\n",
    "print(find_files('.gitkeep', './'))\n",
    "# ['./testdir/subdir2/.gitkeep', './testdir/subdir4/.gitkeep']\n",
    "print(find_files('keep', './'))\n",
    "# []\n",
    "print(find_files('a.c', './'))\n",
    "# ValueError: 'a.c' is not a valid suffix!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Huffmann Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview - Data Compression\n",
    "\n",
    "In general, a data compression algorithm reduces the amount of memory (bits) required to represent a message (data). The compressed data, in turn, helps to reduce the transmission time from a sender to receiver. The sender encodes the data, and the receiver decodes the encoded data. As part of this problem, you have to implement the logic for both encoding and decoding.\n",
    "\n",
    "A data compression algorithm could be either **_lossy_** or **_lossless_**, meaning that when compressing the data, there is a loss (lossy) or no loss (lossless) of information. The **Huffman Coding** is a _lossless_ data compression algorithm. Let us understand the two phases - encoding and decoding with the help of an example.\n",
    "\n",
    "### A. Huffman Encoding\n",
    "\n",
    "Assume that we have a string message `AAAAAAABBBCCCCCCCDDEEEEEE` comprising of 25 characters to be encoded. The string message can be an unsorted one as well. We will have two phases in encoding - building the Huffman tree (a binary tree), and generating the encoded data. The following steps illustrate the Huffman encoding:\n",
    "\n",
    "#### **Phase I - Build the Huffman Tree**  \n",
    "\n",
    "A Huffman tree is built in a bottom-up approach.\n",
    "\n",
    "1.  First, determine the frequency of each character in the message. In our example, the following table presents the frequency of each character.\n",
    "\n",
    "| (Unique) Character | Frequency |\n",
    "|---|---|\n",
    "| A | 7 |\n",
    "| B | 3 |\n",
    "| C | 7 |\n",
    "| D | 2 |\n",
    "| E | 6 |\n",
    "\n",
    "\n",
    "2.  Each row in the table above can be represented as a _node_ having a character, frequency, left child, and right child. In the next step, we will repeatedly require to pop-out the node having the lowest frequency. Therefore, build and sort a _list_ of nodes in the order lowest to highest frequencies. Remember that a _list_ preserves the order of elements in which they are appended.\n",
    "    \n",
    "    We would need our _list_ to work as a **[priority queue](https://en.wikipedia.org/wiki/Priority_queue)**, where a node that has lower frequency should have a higher priority to be popped-out. The following snapshot will help you visualize the example considered above:\n",
    "    \n",
    "\n",
    "![](img/screenshot-2020-04-27-at-5.15.56-pm.png)\n",
    "\n",
    "> Can you come up with other data structures to create a priority queue? How about using a _min-heap_ instead of a list? You are free to choose from anyone.\n",
    "\n",
    "3.  Pop-out two nodes with the minimum frequency from the _priority queue_ created in the above step.\n",
    "\n",
    "4.  Create a new node with a frequency equal to the sum of the two nodes picked in the above step. This new node would become an _internal node_ in the Huffman tree, and the two nodes would become the children. The lower frequency node becomes a left child, and the higher frequency node becomes the right child. Reinsert the newly created node back into the priority queue.  \n",
    "    \n",
    "    **Do you think that this reinsertion requires the sorting of priority queue again?** If yes, then a _min-heap_ could be a better choice due to the lower complexity of sorting the elements, every time there is an insertion.\n",
    "    \n",
    "\n",
    "5.  Repeat steps #3 and #4 until there is a single element left in the priority queue. The snapshots below present the building of a Huffman tree.\n",
    "\n",
    "![](img/huffman-tree-1.png)\n",
    "\n",
    "![](img/huffman-tree-2.png)\n",
    "\n",
    "6.  For each node, in the Huffman tree, assign a bit `0` for left child and a `1` for right child. See the final Huffman tree for our example:\n",
    "\n",
    "![](img/huffman-tree-3.png)\n",
    "\n",
    "#### **Phase II - Generate the Encoded Data**  \n",
    "\n",
    "7.  Based on the Huffman tree, generate unique binary code for each character of our string message. For this purpose, you'd have to traverse the path from root to the leaf node.\n",
    "\n",
    "| (Unique) Character | Frequency | Huffman Code |\n",
    "|---|---|---|\n",
    "| D | 2 | 000 |\n",
    "| B | 3 | 001 |\n",
    "| E | 6 | 01 |\n",
    "| A | 7 | 10 |\n",
    "| C | 7 | 11 |\n",
    "\n",
    "> **Points to Notice**  \n",
    "> \n",
    "> -   Notice that the whole code for any character is **_not_** a prefix of any other code. Hence, the Huffman code is called a **_[Prefix code](https://en.wikipedia.org/wiki/Prefix_code)_**.\n",
    "> -   Notice that the binary code is shorter for the more frequent character, and vice-versa.\n",
    "> -   The Huffman code is generated in such a way that the entire string message would now require a much lesser amount of memory in binary form.\n",
    "> -   Notice that each node present in the original _priority queue_ has become a _leaf node_ in the final Huffman tree.\n",
    "\n",
    "This way, our encoded data would be `1010101010101000100100111111111111111000000010101010101`\n",
    "\n",
    "### B. Huffman Decoding\n",
    "\n",
    "Once we have the encoded data, and the (pointer to the root of) Huffman tree, we can easily decode the encoded data using the following steps:\n",
    "\n",
    "1.  Declare a blank decoded string\n",
    "2.  Pick a bit from the encoded data, traversing from left to right.\n",
    "3.  Start traversing the Huffman tree from the root.\n",
    "    -   If the current bit of encoded data is `0`, move to the left child, else move to the right child of the tree if the current bit is `1`.\n",
    "    -   If a leaf node is encountered, append the (alphabetical) character of the leaf node to the decoded string.\n",
    "4.  Repeat steps #2 and #3 until the encoded data is completely traversed.\n",
    "\n",
    "You will have to implement the logic for both encoding and decoding in the following template. Also, you will need to create the sizing schemas to present a summary.\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "def huffman_encoding(data):\n",
    "    pass\n",
    "\n",
    "def huffman_decoding(data,tree):\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    codes = {}\n",
    "\n",
    "    a_great_sentence = \"The bird is the word\"\n",
    "\n",
    "    print (\"The size of the data is: {}\\n\".format(sys.getsizeof(a_great_sentence)))\n",
    "    print (\"The content of the data is: {}\\n\".format(a_great_sentence))\n",
    "\n",
    "    encoded_data, tree = huffman_encoding(a_great_sentence)\n",
    "\n",
    "    print (\"The size of the encoded data is: {}\\n\".format(sys.getsizeof(int(encoded_data, base=2))))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(encoded_data))\n",
    "\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "\n",
    "    print (\"The size of the decoded data is: {}\\n\".format(sys.getsizeof(decoded_data)))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(decoded_data))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Visualization Resource\n",
    "\n",
    "Check this website to visualize the Huffman encoding for any string message - [Huffman Visualization!](https://people.ok.ubc.ca/ylucet/DS/Huffman.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "----- The bird is the word\n",
      "-------------------------------------------------------\n",
      "The size of the data is: 69\n",
      "The size of the encoded data is: 36\n",
      "The content of the encoded data is: 1110111111101010001100110000101100101101101011111101010000111001100001\n",
      "The size of the decoded data is: 69\n",
      "The content of the encoded data is: The bird is the word\n",
      "-------------------------------------------------------\n",
      "----- \n",
      "-------------------------------------------------------\n",
      "The size of the data is: 49\n",
      "The size of the encoded data is: 49\n",
      "The content of the encoded data is: \n",
      "The size of the decoded data is: 49\n",
      "The content of the encoded data is: \n",
      "-------------------------------------------------------\n",
      "----- 12304905ndylköxykcv 1234uiopxyn.asdf\n",
      "-------------------------------------------------------\n",
      "The size of the data is: 109\n",
      "The size of the encoded data is: 48\n",
      "The content of the encoded data is: 101001101110100110100101110011010111100001011010111111111101101001110111111010101110010001101001101110101001000000001000001111011001110111001111000111000011001000010\n",
      "The size of the decoded data is: 109\n",
      "The content of the encoded data is: 12304905ndylköxykcv 1234uiopxyn.asdf\n",
      "-------------------------------------------------------\n",
      "----- aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-------------------------------------------------------\n",
      "The size of the data is: 112\n",
      "The size of the encoded data is: 24\n",
      "The content of the encoded data is: 000000000000000000000000000000000000000000000000000000000000000\n",
      "The size of the decoded data is: 112\n",
      "The content of the encoded data is: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import sys\n",
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, char, freq):\n",
    "        self.char: str | None = char\n",
    "        self.freq: int = freq\n",
    "        self.left: Node | None = None\n",
    "        self.right: Node | None = None\n",
    "\n",
    "    def __lt__(self, other: 'Node') -> bool:\n",
    "        return other.freq > self.freq\n",
    "\n",
    "def merge_heap(heap: list) -> Node:\n",
    "    \"\"\"Merge a heap list into a tree.\"\"\"\n",
    "    if len(heap) > 1:\n",
    "        child1, child2 = heapq.heappop(heap), heapq.heappop(heap)\n",
    "        parent = Node(None, child1.freq + child2.freq)\n",
    "        parent.left, parent.right = child1, child2\n",
    "        heapq.heappush(heap, parent)\n",
    "        merge_heap(heap)\n",
    "    return heap[0]\n",
    "\n",
    "def text_to_tree(text: str) -> Node:\n",
    "    \"\"\"Convert text to a min-heap frequency tree.\"\"\"\n",
    "    frequencies = dict(Counter(text))\n",
    "    # edge case empty text:\n",
    "    if frequencies == {}:\n",
    "        return Node(\"\", 0)\n",
    "\n",
    "    heap = [Node(key, value) for key, value in frequencies.items()]\n",
    "    heapq.heapify(heap)\n",
    "    tree = merge_heap(heap)\n",
    "    return tree\n",
    "\n",
    "def create_codes(node: Node, code: str = \"\") -> dict:\n",
    "    \"\"\"Create huffman codes.\"\"\"\n",
    "    # edge case: single character in text\n",
    "    if code == \"\" and node.left is None:\n",
    "        code = \"0\"\n",
    "\n",
    "    codes = {}\n",
    "    if node.char is not None:\n",
    "        codes[node.char] = code\n",
    "    else:\n",
    "        codes |= create_codes(node.left, code+str(0))\n",
    "        codes |= create_codes(node.right, code+str(1))\n",
    "    return codes\n",
    "\n",
    "def huffman_encoding(data: str) -> Tuple[str, Node]:\n",
    "    \"\"\"Encode data with huffman codes.\"\"\"\n",
    "    tree = text_to_tree(data)\n",
    "    codes = create_codes(tree)\n",
    "    code = ''.join([codes[char] for char in data])\n",
    "    return code, tree\n",
    "\n",
    "def huffman_decoding(data: str, tree: Node) -> str:\n",
    "    \"\"\"Decode huffman codes to text.\"\"\"\n",
    "    # edge case: single character in text\n",
    "    if tree.left is None:\n",
    "        return ''.join([tree.char for _ in data])\n",
    "\n",
    "    decoded = \"\"\n",
    "    node = tree\n",
    "    for pos, c in enumerate(data):\n",
    "        match c:\n",
    "            case \"0\": node = node.left\n",
    "            case \"1\": node = node.right\n",
    "        if node.char:\n",
    "            decoded += node.char\n",
    "            decoded += huffman_decoding(data[pos+1:], tree)\n",
    "            break\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def huffmann_test(text):\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"----- {text}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"The size of the data is: {}\".format(sys.getsizeof(text)))\n",
    "\n",
    "    encoded_data, tree = huffman_encoding(text)\n",
    "\n",
    "    if len(encoded_data) == 0:\n",
    "        print(\"The size of the encoded data is: {}\".format(sys.getsizeof(encoded_data)))\n",
    "    else:\n",
    "        print(\"The size of the encoded data is: {}\".format(sys.getsizeof(int(encoded_data, base=2))))\n",
    "    print(\"The content of the encoded data is: {}\".format(encoded_data))\n",
    "\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "\n",
    "    print(\"The size of the decoded data is: {}\".format(sys.getsizeof(decoded_data)))\n",
    "    print(\"The content of the encoded data is: {}\".format(decoded_data))\n",
    "\n",
    "huffmann_test(\"The bird is the word\")\n",
    "huffmann_test(\"\")\n",
    "huffmann_test(\"12304905ndylköxykcv 1234uiopxyn.asdf\")\n",
    "huffmann_test(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Active Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Windows Active Directory, a group can consist of user(s) and group(s) themselves. We can construct this hierarchy as such. Where User is represented by str representing their ids.\n",
    "\n",
    "```python\n",
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []\n",
    "        self.users = []\n",
    "\n",
    "    def add_group(self, group):\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self, user):\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "sub_child_user = \"sub_child_user\"\n",
    "sub_child.add_user(sub_child_user)\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)\n",
    "```\n",
    "\n",
    "Write a function that provides an efficient look up of whether the user is in a group.\n",
    "\n",
    "```python\n",
    "def is_user_in_group(user, group):\n",
    "    \"\"\"\n",
    "    Return True if user is in the group, False otherwise.\n",
    "\n",
    "    Args:\n",
    "      user(str): user name/id\n",
    "      group(class:Group): group to check user membership against\n",
    "    \"\"\"\n",
    "    return None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []\n",
    "        self.users = []\n",
    "\n",
    "    def add_group(self, group):\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self, user):\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "def is_user_in_group(user, group):\n",
    "    \"\"\"\n",
    "    Return True if user is in the group, False otherwise.\n",
    "\n",
    "    Args:\n",
    "      user(str): user name/id\n",
    "      group(class:Group): group to check user membership against\n",
    "    \"\"\"\n",
    "    if user in group.get_users():\n",
    "        return True\n",
    "    else:\n",
    "        for group in group.get_groups():\n",
    "            return is_user_in_group(user, group)\n",
    "    return False\n",
    "\n",
    "\n",
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "sub_child_user = \"sub_child_user\"\n",
    "sub_child.add_user(sub_child_user)\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)\n",
    "\n",
    "print(is_user_in_group(sub_child_user, child))\n",
    "# True\n",
    "print(is_user_in_group(sub_child_user, parent))\n",
    "# True\n",
    "print(is_user_in_group(\"Some User\", sub_child))\n",
    "# False\n",
    "print(is_user_in_group(\"\", parent))\n",
    "# False\n",
    "print(is_user_in_group(None, parent))\n",
    "# False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Blockchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [Blockchain](https://en.wikipedia.org/wiki/Blockchain) is a sequential chain of records, similar to a linked list. Each block contains some information and how it is connected related to the other blocks in the chain. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. For our blockchain we will be using a [SHA-256](https://en.wikipedia.org/wiki/SHA-2) hash, the [Greenwich Mean Time](https://en.wikipedia.org/wiki/Greenwich_Mean_Time) when the block was created, and text strings as the data.\n",
    "\n",
    "Use your knowledge of linked lists and hashing to create a blockchain implementation.\n",
    "\n",
    "![](./img/blockchain.png)\n",
    "\n",
    "We can break the blockchain down into three main parts.\n",
    "\n",
    "First is the information hash:\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "def calc_hash(self):\n",
    "      sha = hashlib.sha256()\n",
    "\n",
    "      hash_str = \"We are going to encode this string of data!\".encode('utf-8')\n",
    "\n",
    "      sha.update(hash_str)\n",
    "\n",
    "      return sha.hexdigest()\n",
    "```\n",
    "\n",
    "We do this for the information we want to store in the block chain such as transaction time, data, and information like the previous chain.\n",
    "\n",
    "The next main component is the block on the blockchain:\n",
    "\n",
    "```python\n",
    "class Block:\n",
    "\n",
    "    def __init__(self, timestamp, data, previous_hash):\n",
    "      self.timestamp = timestamp\n",
    "      self.data = data\n",
    "      self.previous_hash = previous_hash\n",
    "      self.hash = self.calc_hash()\n",
    "```\n",
    "\n",
    "Above is an example of attributes you could find in a `Block` class.\n",
    "\n",
    "Finally you need to link all of this together in a block chain, which you will be doing by implementing it in a linked list. All of this will help you build up to a simple but full blockchain implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Blocks.\n",
      "\n",
      "--- Blockchain Size: 1 ---\n",
      "Index: 1\n",
      "Timestamp: 2022-07-07T20:11:11.996957\n",
      "Data: Dummy Data1\n",
      "Previous Hash: 0\n",
      "Hash: c22e6862cf3eebf241246266c9dcf63db204fc26d54f5e699359166cb3883e42\n",
      "\n",
      "--- Blockchain Size: 2 ---\n",
      "Index: 1\n",
      "Timestamp: 2022-07-07T20:11:11.996957\n",
      "Data: Dummy Data1\n",
      "Previous Hash: 0\n",
      "Hash: c22e6862cf3eebf241246266c9dcf63db204fc26d54f5e699359166cb3883e42\n",
      "--->\n",
      "Index: 2\n",
      "Timestamp: 2022-07-07T20:11:11.997042\n",
      "Data: Dummy Data2\n",
      "Previous Hash: c22e6862cf3eebf241246266c9dcf63db204fc26d54f5e699359166cb3883e42\n",
      "Hash: 96496e22c92946011ec46c43cb624480a252f44727e4d09a7f1e29e31b32a5b6\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Block:\n",
    "\n",
    "    def __init__(self, data, previous_hash, index):\n",
    "        self.index = index\n",
    "        self.timestamp = datetime.utcnow().isoformat()\n",
    "        self.data = data\n",
    "        self.previous_hash = previous_hash\n",
    "        self.hash = self.calc_hash(data)\n",
    "        self.next = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Index: {self.index}\\n\"\\\n",
    "                f\"Timestamp: {self.timestamp}\\n\"\\\n",
    "                f\"Data: {self.data}\\n\"\\\n",
    "                f\"Previous Hash: {self.previous_hash}\\n\"\\\n",
    "                f\"Hash: {self.hash}\"\n",
    "\n",
    "    def calc_hash(self, data):\n",
    "        sha = hashlib.sha256()\n",
    "        sha.update(data.encode('utf-8'))\n",
    "        return sha.hexdigest()\n",
    "\n",
    "    \n",
    "class Blockchain:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.size = 0\n",
    "        self.root = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.root is None:\n",
    "            return \"No Blocks.\"\n",
    "\n",
    "        blocks = []\n",
    "        current = self.root\n",
    "        while current:\n",
    "            blocks.append(str(current))\n",
    "            current = current.next\n",
    "\n",
    "        return f\"\\n--- Blockchain Size: {self.size} ---\\n\" + \"\\n--->\\n\".join(blocks)\n",
    "\n",
    "    def add_block(self, data):\n",
    "        self.size += 1\n",
    "\n",
    "        if self.root is None:\n",
    "            self.root = Block(data, 0, self.size)\n",
    "            return\n",
    "        \n",
    "        current = self.root\n",
    "        while current.next:\n",
    "            current = current.next\n",
    "        \n",
    "        current.next = Block(data, current.hash, self.size)\n",
    "\n",
    "\n",
    "b = Blockchain()\n",
    "print(b)\n",
    "# No Blocks.\n",
    "b.add_block(\"Dummy Data1\")\n",
    "print(b)\n",
    "# --- Blockchain Size: 1 --- ...\n",
    "b.add_block(\"Dummy Data2\")\n",
    "print(b)\n",
    "# --- Blockchain Size: 2 --- ...\n",
    "print(b.root.hash == b.root.next.previous_hash)\n",
    "# True\n",
    "print(b.root.previous_hash)\n",
    "# 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Union and Intersection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37c5d73273564d1b0e1dc444df20e27e3340301b5cfd725c2b020aa4cb53d242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
